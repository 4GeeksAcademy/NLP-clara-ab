{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Proyecto Natural Language Processing (NLP):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n",
                        "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n",
                        "[nltk_data] Downloading package punkt_tab to /home/vscode/nltk_data...\n",
                        "[nltk_data]   Package punkt_tab is already up-to-date!\n",
                        "[nltk_data] Downloading package wordnet to /home/vscode/nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 63,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Librería para la declaración y uso de Data Frames:\n",
                "import pandas as pd\n",
                "\n",
                "# Librería para la utilización de Expresiones Regulares:\n",
                "import re\n",
                "\n",
                "# Librería para la utilización de herramientas para NLP:\n",
                "import nltk\n",
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "\n",
                "nltk.download('stopwords')\n",
                "nltk.download('punkt')\n",
                "nltk.download('punkt_tab')\n",
                "nltk.download('wordnet')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 1 - Lectura de Datos: "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "En primer lugar, es necesario **leer y guardar la información** en una variable para poder empezar a trabajar con ella.\n",
                "\n",
                "Para ello, se ha guaradado el archivo con todos los datos en la ruta: */workspaces/NLP-clara-ab/data/raw/url_spam.csv* y se ha cargado en un Data Frame:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Lectura del CSV con los datos, dada la ruta donde se guarda el archivo (se ha evitado cargar la primera columna con los índices de las filas):\n",
                "df = pd.read_csv ('/workspaces/NLP-clara-ab/data/raw/url_spam.csv', sep = \",\");\n",
                "\n",
                "# Configuración de pandas para mostrar todas las columnas del DataFrame sin truncarlas al visualizarlo:\n",
                "pd.set_option('display.max_columns', None);\n",
                "\n",
                "# Se muestran las 5 primeras filas del Data Frame:\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez se ha cargado correctamente la información en el Data Frame df es interesante evaluar la **cantidad de información que se tiene**. Para ello, se recurre al atributo `shape` del Data Frame:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " El archivo cargado contiene 2999 URLs\n"
                    ]
                }
            ],
            "source": [
                "# Se utiliza el atributo shape del Data Frame para conocer cuánta información está cargada:\n",
                "print(f\" El archivo cargado contiene {df.shape[0]} URLs\"); "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Además, tal y como se ha visto en el **breve resumen** mostrado a partir de `.head()` la variable a predecir, `is_spam` tiene dos valores posibles: `True` or `False`. \n",
                "\n",
                "En este caso, nos interesa predecir si una URL es SPAM, es decir, **detectar el `TRUE`**. Por lo que se va a realizar un cambio de forma que, en todas las filas donde la columna `is_spam` sea `True`, se convertirán a `1` y donde haya un `False` se convertirán a `0`. \n",
                "\n",
                "Para no tener problemas, es importante comprobar, primero el **tipo de variable** que se encuentra en la columna `is_spam`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "url        object\n",
                        "is_spam      bool\n",
                        "dtype: object\n"
                    ]
                }
            ],
            "source": [
                "# Se imprimen los tipos de variables de las dos columnas del DataFrame:\n",
                "print(df.dtypes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora que se sabe que es un **boolean**, se puede realizar la conversión con la función `map()` de forma segura:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...        1\n",
                            "1                             https://www.hvper.com/        1\n",
                            "2                 https://briefingday.com/m/v4n3i4f3        1\n",
                            "3   https://briefingday.com/n/20200618/m#commentform        0\n",
                            "4                        https://briefingday.com/fan        1"
                        ]
                    },
                    "execution_count": 67,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Se codifica la columna objetivo:\n",
                "df['is_spam'] = df['is_spam'].astype(bool).map({True: 1, False: 0})\n",
                "\n",
                "# Se comprueba que se ha codificado correctamente: \n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 2 - Análisis Exploratorio de Datos (Previo):"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Antes de pasar el preprocesado de texto, donde se prepara al conjunto de datos para el análisis, es necesario realizar un **análisis exploratorio de los datos previo** de forma que se puedan **eliminar redundancias o datos faltantes** y no trabajar sobre ellos de forma innecesaria en el paso siguiente. \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Paso 2.1 - Análisis de Duplicados:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Hay un total de 630 URLs duplicadas.\n"
                    ]
                }
            ],
            "source": [
                "# Se utiliza el método .duplicated() para identificar las URL repetidas dentro del DataFrame:\n",
                "print(f\" Hay un total de {df.duplicated().sum()} URLs duplicadas.\");"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Se han encontrado un total de 630 URLs duplicadas que se deben eliminar:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " Hay un total de 0 URLs duplicadas.\n"
                    ]
                }
            ],
            "source": [
                "# Se eliminan los duplicados:\n",
                "df_clean = df.drop_duplicates();\n",
                "\n",
                "# Se comprueba que ya no quedan duplicados:\n",
                "print(f\" Hay un total de {df_clean.duplicated().sum()} URLs duplicadas.\");"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Paso 2.2 - Análisis de Nulos:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " El 0.0 % de las filas presentan, al menos, un valor nulo\n"
                    ]
                }
            ],
            "source": [
                "# Se comprueba el porcentaje de filas que presentan al menos un valor nulo:\n",
                "print(f\" El {round(df_clean.isnull().any(axis=1).mean()*100, 2)} % de las filas presentan, al menos, un valor nulo\");"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "No tenemos ninguna fila con valores nulos."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Paso 3 - Preprocesamiento de Texto:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez ya se tiene guardado el conjunto de datos con una breve **limpieza previa**, se puede pasar a realizar un **preprocesado del texto a estudiar**, en este caso  las URLs.\n",
                "\n",
                "El **preprocesamiento de texto** es un paso **crucial** en el análisis de información textual, dado que ayuda a **transformar la información en bruto en un formato más estructurado y útil** para modelos de Machine Learning. De esta forma, se ayuda a eliminar el *ruido* desechando los patrones, *a priori*, irrelevantes. \n",
                "\n",
                "Para ello, se van a utilizar **dos librerías** imprescindibles en el procesado de texto: \n",
                "\n",
                "**- `re`:** Librería de Python utilizada para trabajar con **expresiones regulares** (secuencia de caracteres que definen un patrón de búsqueda). Es útil para **segementar y limpiar textos** mediante diferentes patrones. En este caso, va a permitir dividir las URLs por caracteries especiales y eliminar todos los elementos no deseados. \n",
                "\n",
                "**- `nltk` Natural Language Toolkit:** Librería de Python con **herramientas** útiles para el procesado de lenguaje natural como *stopwords*, lematización y tokenización, lo que facilita la **normalización** del texto antes de aplicar cualquier modelo de Machine Learning. \n",
                "\n",
                "En este caso, se van a realizar 7 pasos: \n",
                "\n",
                "1. Conversión del texto a minúscula\n",
                "\n",
                "2. Segmentación de las URLs\n",
                "\n",
                "3. Eliminado de palabras sin valor y espacios\n",
                "\n",
                "4. Tokenización\n",
                "\n",
                "5. Eliminado de *StopWords*\n",
                "\n",
                "6. Lematización\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Para poder realizar todo este preprocesado, se va a utilizar una **función** que reciba como input el texto a preprocesar y se le devuelva totalmente procesado:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_text (url):\n",
                "\n",
                "    # 1. Conversión a minúsculas:\n",
                "    url = url.lower();\n",
                "      \n",
                "    # 2. Eliminado de palabras irrelevantes:\n",
                "    url = re.sub(r'https?://|www\\.', '', url); # Protocolo web\n",
                "    url = re.sub(r'\\s+[a-zA-Z]\\s+', \" \", url) # Espacios en blanco\n",
                "    url = re.sub(r'\\s*\\d+\\s*', ' ', url)  # Elimina números aislados\n",
                "    url = re.sub(r'\\b[a-zA-Z]*\\d+[a-zA-Z]*\\b', ' ', url)  # Borra tokens con mezcla de letras y números\n",
                "    \n",
                "    # Solo texto\n",
                "    url = re.sub(r'[^\\w\\s]|[\\d]', ' ', url)\n",
                "    # Eliminación de los espacios adicionales\n",
                "    url = re.sub(r'\\s+', ' ', url).strip()\n",
                "\n",
                "    # 3. Segmentación de las URLs:\n",
                "    tokens = re.split(r'[\\/\\.\\?\\=\\&\\-_]', url);\n",
                "\n",
                "\n",
                "    \n",
                "    # Tokenización del texto\n",
                "    #tokens = word_tokenize(url)\n",
                "\n",
                "    # 6. Eliminación de stopwords\n",
                "    stop_words = set(stopwords.words('english'))\n",
                "    tokens = [token for token in tokens if token not in stop_words]\n",
                "\n",
                "    # Lematización de palabras\n",
                "    lemmatizer = WordNetLemmatizer()\n",
                "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
                "\n",
                "    return ' '.join(tokens)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "URL antes de ser preprocesada:\n",
                        " https://cloudwars.co/covid-19/zoom-quarter-10-eye-popping-stats-from-techs-new-superstar/\n",
                        "--------------------------------------------------\n",
                        "URL tras ser preprocesado:\n",
                        " cloudwars co covid zoom quarter eye popping stats from techs new superstar\n"
                    ]
                }
            ],
            "source": [
                "# Ejemplo de aplicación de la función de preprocesado para un tweet aleatorio\n",
                "url_random = df_clean.sample(1).url.values[0]\n",
                "print(f'URL antes de ser preprocesada:\\n {url_random}')\n",
                "url_random_prepro = preprocess_text(url_random)\n",
                "print('-'*50)\n",
                "print(f'URL tras ser preprocesado:\\n {url_random_prepro}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Paso 3.1 - Conversión a Minúscula:"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "La** conversión de la URLs a minúsculas** asegura que las variaciones en el caso de las letras no afecten al análisis´. El hecho de que una palabra lleve o no minúscula, **no aporta información relevante** a la clasificación por lo que es mejor trabajar con una **uniformidad en los datos**. \n",
                "\n",
                "Para conseguirlo, se va a utilizar la función `lower()` sobre la columna de URLs.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df_' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Se pasa todo a minúsculas:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_\u001b[49m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'df_' is not defined"
                    ]
                }
            ],
            "source": [
                "# Se pasa todo a minúsculas:\n",
                "df_"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
